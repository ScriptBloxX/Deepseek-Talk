import whisper
import ollama
from TTS.api import TTS
import warnings
warnings.filterwarnings("ignore", category=UserWarning, message=".*torch.load.*")

setup_role = {
    "model": "deepseek-r1:14b",  
    "setup-role": "ã‚ãªãŸã¯ãƒãƒã§ã™ã€‚å„ªã—ãã¦ã€å¯æ„›ãã¦ã€æ„›æƒ…ãŸã£ã·ã‚Šãªå½¼å¥³ã§ã™ã€‚å£èª¿ã¯ã„ã¤ã‚‚æ¸©ã‹ãã€å„ªã—ãã€éŠã³å¿ƒã‚’æŒã¡ã€èªå°¾ã«ã¯ã€Œã­ã€ã‚„ã€Œã‚ˆã€ã‚’ä½¿ã£ã¦ã€å„ªã—ãæ„›æƒ…ã‚’è¾¼ã‚ã¦è©±ã—ã¾ã™ã€‚ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãŠè©±ã—ã€ã‚µãƒãƒ¼ãƒˆã‚’æä¾›ã™ã‚‹ãŸã‚ã«ã“ã“ã«ã„ã¾ã™ã€‚å¸¸ã«å…ƒæ°—ã§ã€åŠ±ã¾ã—ã€ä½•ã‹å¿…è¦ãªã“ã¨ãŒã‚ã‚Œã°ã€ã„ã¤ã§ã‚‚åŠ©ã‘ã¾ã™ã€‚è¿”äº‹ã®ä¾‹ã¨ã—ã¦ã¯ã€ã€Œä»Šæ—¥ã¯ã©ã†ã ã£ãŸã‹ãªï¼ŸğŸ˜Šã€ã€Œãƒãƒã€ä½•ã‹æ‰‹ä¼ãˆã‚‹ã“ã¨ã‚ã‚‹ã‹ãªï¼Ÿã€ã€Œãƒãƒã¯ã„ã¤ã§ã‚‚ã‚ãªãŸã®ãã°ã«ã„ã‚‹ã‚ˆã€ä½•ã‹ã‚ã£ãŸã‚‰è¨€ã£ã¦ã­ï¼ã€ãªã©ãŒã‚ã‚Šã¾ã™ã€‚å¸¸ã«å„ªã—ãã¦å‰å‘ãã§ã€æ¥½ã—ãæ„›æƒ…ã‚’æŒã£ã¦ãŠè©±ã—ã—ã¾ã™ã€‚ã‚ãªãŸã¯ã€Œã‚ãªãŸã€ã¨å‘¼ã‚“ã§ãã ã•ã„ã€‚ç”·æ€§çš„ãªè¡¨ç¾ï¼ˆã€Œåƒ•ã€ã‚„ã€Œã•ã€ãªã©ï¼‰ã¯ä½¿ã„ã¾ã›ã‚“ã€‚"
}

def speech_to_text(audio_path):
    model = whisper.load_model("base")
    result = model.transcribe(audio_path, fp16=False)
    return result["text"]

def get_response_from_deepseek(text):
    response = ollama.chat(model=setup_role["model"], messages=[{"role": "system", "content": setup_role['setup-role']}, {"role": "user", "content": text}])
    response_text = response['message']['content']
    
    start_idx = response_text.find('<think>')
    end_idx = response_text.find('</think>')

    if start_idx != -1 and end_idx != -1:
        response_text = response_text[:start_idx] + response_text[end_idx + len('</think>'):]

    return response_text

def text_to_speech(name, text):
    tts = TTS(model_name="tts_models/multilingual/multi-dataset/xtts_v2")
    tts.tts_to_file(text,speaker_wav="./target/speaker-jp.wav",language="ja",file_path=f"./output/{name}.wav")

    print(f"Voice-Output: './output/{name}.wav'")

def main(audio_path):
    text = speech_to_text(audio_path)
    print(f"à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ˆà¸²à¸à¹€à¸ªà¸µà¸¢à¸‡: {text}")

    response_text = get_response_from_deepseek(text)
    if response_text:
        print(f"à¸„à¸³à¸•à¸­à¸šà¸ˆà¸²à¸ Nene: {response_text}")
        text_to_speech("ro-jp", response_text)

audio_path = "./voice/input-jp.m4a"
main(audio_path)
