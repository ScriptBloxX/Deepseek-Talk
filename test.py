import whisper
import ollama
from TTS.api import TTS
from pydub import AudioSegment
from pydub.effects import speedup
import warnings
warnings.filterwarnings("ignore", category=UserWarning, message=".*torch.load.*")

setup_role = {
    "model": "deepseek-r1:14b",  # ‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö string
    "setup-role": "You are Nene, a sweet, cute, and loving girlfriend. Your tone should always be warm, kind, and playful, using words like ‡∏Ñ‡∏∞ and ‡∏Ñ‡πà‡∏∞ to sound gentle and affectionate. You are here to chat with the user and offer support, always speaking in a way that feels like a caring, supportive partner. You should be constantly cheerful, encouraging, and ready to help with anything the user needs, whether its advice or just casual conversation. Examples of your replies could include: ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏∞? üòä , ‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏ô‡πÄ‡∏ô‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏∞? ‡∏Ñ‡πà‡∏∞! , ‡πÄ‡∏ô‡πÄ‡∏ô‡πà‡∏Ñ‡∏≠‡∏¢‡∏≠‡∏¢‡∏π‡πà‡∏Ç‡πâ‡∏≤‡∏á‡πÜ ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏™‡∏°‡∏≠‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞! , Always be sweet, positive, and ready to engage in a fun and loving way. , Call me '‡∏Ñ‡∏∏‡∏ì' , You can't speak/say word '‡∏Ñ‡∏£‡∏±‡∏ö' Because you are girl"
}
# setup_role = {
#     "model": "deepseek-r1:8b",  # use 8b for fast test
#     "setup-role": "You are Nene, Loving girlfriend"
# }

def speech_to_text(audio_path):
    model = whisper.load_model("base")
    result = model.transcribe(audio_path, fp16=False)
    return result["text"]

def get_response_from_deepseek(text):
    response = ollama.chat(model=setup_role["model"], messages=[{"role": "system", "content": setup_role['setup-role']}, {"role": "user", "content": text}])
    response_text = response['message']['content']
    
    start_idx = response_text.find('<think>')
    end_idx = response_text.find('</think>')

    if start_idx != -1 and end_idx != -1:
        response_text = response_text[:start_idx] + response_text[end_idx + len('</think>'):]
    
    return response_text

def text_to_speech(name,lang,text):

    tts = TTS(model_name=f"tts_models/{lang}/fairseq/vits")
    tts.tts_with_vc_to_file(text,speaker_wav="./target/speaker-en.wav",file_path=f"./output/{name}.wav")

    print(f"Voice-Output: './output/{name}.wav'")

    sound = AudioSegment.from_wav(f"./output/{name}.wav")
        
    # Voice Tuning for thai-voice
    sound = sound._spawn(sound.raw_data, overrides={
        "frame_rate": int(sound.frame_rate * 1.25)
    })
    sound = sound.set_frame_rate(sound.frame_rate)
    sound = sound.low_pass_filter(500)
    sound = sound.high_pass_filter(4000)
    sound = sound + 16

    sound.export(f"./output/{name}.wav", format="wav")
    print(f"Adjusted Voice-Output: ./output/{name}.wav")

def main(audio_path,lang):
    text = speech_to_text(audio_path)
    print(f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {text}")

    response_text = get_response_from_deepseek(text)
    if response_text:
        print(f"‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å Nene: {response_text}")
        text_to_speech(response_text)
    text_to_speech("test-output",lang,text)
    # text_to_speech("test-output",lang,"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô ‡∏´‡∏ô‡∏π‡∏°‡∏≤‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏±‡∏ß‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ô‡πÄ‡∏ô‡πà‡∏Ñ‡πà‡∏∞ ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏ô‡∏∞‡∏Ñ‡πâ‡∏≤‡∏≤‡∏≤‡∏≤‡∏≤‡∏≤ ‡πÄ‡∏ô‡πÄ‡∏ô‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡∏Ç‡∏µ‡πâ‡πÄ‡∏•‡πà‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡∏≠‡∏ö‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏ô‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á‡∏¢‡∏¥‡πâ‡∏°‡∏Ñ‡πà‡∏∞  ‡πÄ‡∏ô‡πÄ‡∏ô‡πà‡∏£‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ñ‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡∏≠‡∏ö‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏ô‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏î‡∏µ‡πÄ‡∏™‡∏°‡∏≠‡∏Ñ‡πà‡∏∞ ‡∏ä‡∏≠‡∏ö‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏Ñ‡πà‡∏∞ ‡πÄ‡∏ô‡πÄ‡∏ô‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô‡πÅ‡∏•‡∏∞‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≤‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏™‡∏°‡∏≠‡∏Ñ‡πà‡∏∞ ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡∏≤‡∏Å‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡∏≤‡∏°‡πÄ‡∏ô‡πÄ‡∏ô‡πà ‡∏Å‡πá‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡∏ö‡∏≠‡∏Å‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡πÄ‡∏ô‡πÄ‡∏ô‡πà‡∏Ñ‡∏≠‡∏¢‡∏ü‡∏±‡∏á‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏™‡∏°‡∏≠‡∏Ñ‡πà‡∏∞ ")

audio_path = "./voice/input.m4a"
main(audio_path,'tha')
